Title,Number,Body,State,Created At,Closed At,User,Commits,Additions,Deletions,Changed Files
feat: add ci for prettier check and build,48,"Added CI for prettier check and build on PRs and pushes.
Resolves #47 ",open,2023-11-21T18:47:03Z,,kunal00000,3,55,2,3
Added Directory Exclusion,27,"Recursive directory exclusion (#9) and user configurable through config.ts. A list of excluded parent directories is read into an array to be checked against during the crawling process and skipped if found. Pretty quick and dirty and could probably use some optimization. 

Tidied up some related comments as well to make things a little clearer. ",open,2023-11-18T19:53:14Z,,bleachedsleet,1,28,2,2
"Refactor getPageHtml function to handle selector not found case, using body as fallback. Add support for downloading URLs from sitemap.xml. Update comments to let know that sitemap is supported",26,"This pull request includes several changes to improve the functionality of the code:

1. Refactored the `getPageHtml` function to handle the case when the specified selector is not found on the page. In this case, the function now falls back to using the `body` selector to retrieve the page content.

2. Added a try-catch block to handle the case when the specified selector is not found during the page crawl. If the selector is not found, a warning message is logged and the function falls back to using the `body` selector.

3. Added support for downloading URLs from a sitemap.xml file. If the provided URL is a sitemap, all pages listed in the sitemap will be crawled.

4. Updated comments in the code to indicate that sitemap support has been added.

These changes improve the robustness and flexibility of the code, allowing it to handle cases where the specified selector is not found and enabling the crawling of pages listed in a sitemap.

Fixes #16",open,2023-11-18T14:32:13Z,,guillermoscript,9,64,10,3
Added the ability to crawl content links,15,"Hi, I've added a deep web crawler that extracts links as an extension to this article.

- `withoutSelector` crawls internal external links without a selector.
- `attributeWhitelist` allows you to optimize performance by whitelisting HTML attributes to be preserved.
- `isContentLink` determines whether to enable crawling internal external links.

I hope you find this PR useful. If you have any questions, please feel free to reach out to me.",open,2023-11-17T14:10:59Z,,994AK,3,3431,3611,3
Added 'Exclude' URL Feature to Scraper,12,"I added a small but handy feature üèóÔ∏è 

Now you can specify URLs to be ignored üôà during the crawls. 
This should help skip stuff you don‚Äôt need and keep the output data cleaner.

### What's in this PR:

1. Added an exclude field in config.ts for patterns we want to skip.
2. Tweaked requestHandler in src/main.ts to filter out these URLs.

This PR will close #9 ü•≥ ",open,2023-11-17T04:28:18Z,,adamlaz,4,16,1,3
